import { Injectable, InternalServerErrorException, Logger } from '@nestjs/common';
import OpenAI from 'openai';
import { ConfigService } from '@nestjs/config';
import { promisify } from 'util';
import { exec } from 'child_process';
import * as fs from 'fs';
import * as path from 'path';
import { CONST_AI_MODEL } from 'src/constant/app.constants';
import { InvoiceDto } from 'src/invoice/dto/invoice.dto';

const execPromise = promisify(exec);

@Injectable()
export class AIService {
  private readonly openai: OpenAI;
  private readonly logger = new Logger("AIService");

  constructor(private configService: ConfigService) {
    this.openai = new OpenAI({
      apiKey: this.configService.get<string>('XAI_API_KEY') || 'your_api_key', // Fallback for dev; prefer env vars
      baseURL: 'https://api.x.ai/v1',
      timeout: 360000, // 6-minute timeout for reasoning models
    });
  }

  async getOllamaResponse(model: string, systemRole: string, prompt: string): Promise<InvoiceDto | undefined> {
    let responseJson: InvoiceDto;
    let result = '';

    try {
      const response = await fetch(`${this.configService.get<string>('OLLAMA_URL')}/generate`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: model,
          messages: [
            {
              role: 'system',
              content: systemRole
            },
            {
              role: 'user',
              content: prompt,
            },
          ],
        }),
      });
      const reader = response.body?.getReader();

      if (reader) {
        const decoder = new TextDecoder();
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          const chunk = decoder.decode(value);
          // Each chunk is JSON like {"response":"Hello","done":false}
          const lines = chunk.trim().split('\n');
          for (const line of lines) {
            const data = JSON.parse(line);
            if (data.response) result += data.response;
          }
        }
      }

        responseJson = JSON.parse(result.replace(/```json/g, '').replace(/```/g, ''));
        responseJson.model = model;
        responseJson.token = 0;
        return responseJson;

    } catch (err) {
      this.logger.error("Error occured: ", err);
      this.logger.error(`Result: `, result);
    }
  }

  async getGrokResponse(systemRole: string, prompt: string): Promise<InvoiceDto | undefined> {
    try {
      const completion = await this.openai.chat.completions.create(
        {
          model: CONST_AI_MODEL.GROK,
          messages: [
            {
              role: 'system',
              content: systemRole,
            },
            {
              role: 'user',
              content: prompt,
            },
          ],
        }
      );

      const response = completion.choices[0]?.message?.content;

      if (!response) {
        throw new InternalServerErrorException('No response received from Grok API');
      }

      const responseJson: InvoiceDto = JSON.parse(response.replace(/```json/g, '').replace(/```/g, ''));
      responseJson.token = completion.usage?.total_tokens;
      responseJson.model = CONST_AI_MODEL.GROK;
      return responseJson;
    } catch (error) {
      throw new InternalServerErrorException(`Failed to fetch Grok response: ${error.message}`);
    }
  }

  async getWhisperTranscription(buffer: Buffer): Promise<string> {
    // const tmpDir = path.join(path.dirname, 'whisper-audio');
    const tmpDir = path.resolve(__dirname, '../../transcription');
    if (!fs.existsSync(tmpDir)) fs.mkdirSync(tmpDir, { recursive: true });

    const webmPath = path.join(tmpDir, `temp-${Date.now()}.webm`);
    const wavPath = webmPath.replace('.webm', '.wav');
    const txtPath = wavPath.replace('.wav', '.txt');

    // Write the buffer temporarily
    fs.writeFileSync(webmPath, buffer);

    try {
      // Convert WebM â†’ WAV
      await execPromise(`ffmpeg -y -i "${webmPath}" -ar 16000 -ac 1 -c:a pcm_s16le "${wavPath}"`);

      // Run Whisper on the WAV file
      await execPromise(`whisper "${wavPath}" --model turbo --output_format txt --output_dir transcription`);

      // Read the transcription result
      const transcription = fs.existsSync(txtPath)
        ? fs.readFileSync(txtPath, 'utf8')
        : 'No transcription output found.';

      return transcription.trim();
    } finally {
      // Cleanup temp files
      [webmPath, wavPath, txtPath].forEach((f) => {
        if (fs.existsSync(f)) fs.unlinkSync(f);
      });
    }
  }

}
